!pip install faiss-cpu langchain transformers

import os
import json
import faiss
import numpy as np
from transformers import AutoTokenizer

# Set directory where JSON files are stored in Colab
DATA_DIR = "/content/legal_data"

# Create directory if not exists
os.makedirs(DATA_DIR, exist_ok=True)

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained("Qwen/Qwen1.5-0.5B", trust_remote_code=True)

# Function to load and process JSON files
def load_legal_sections():
    legal_data = []

    for filename in os.listdir(DATA_DIR):
        if filename.endswith(".json"):
            filepath = os.path.join(DATA_DIR, filename)
            with open(filepath, "r", encoding="utf-8") as file:
                data = json.load(file)

                for section in data:
                    section_text = f"{section.get('section_title', 'Unknown Section')}: {section.get('section_desc', 'No description available.')}"
                    legal_data.append({
                        "section_number": section.get("section", "Unknown"),
                        "section_title": section.get("section_title", "Unknown Section"),
                        "act_name": filename.replace(".json", ""),
                        "text": section_text
                    })

    return legal_data

# Function to generate embeddings correctly
def get_embedding(text):
    tokens = tokenizer(text, return_tensors="pt", padding="max_length", max_length=512, truncation=True)["input_ids"]
    tokens = tokens.squeeze().detach().cpu().numpy()  # Convert to NumPy array
    return np.array(tokens, dtype="float32")  # âœ… Always 512 dimensions


# Load legal sections
legal_sections = load_legal_sections()

# Generate embeddings & metadata
embeddings = []
metadata = []

for section in legal_sections:
    embedding = get_embedding(section["text"])
    embeddings.append(embedding)
    metadata.append(section)

for i, emb in enumerate(embeddings[:5]):
    print(f"Embedding {i} shape: {np.array(emb).shape}")


embeddings = np.array(embeddings, dtype="float32")

# Check shape
print(f"Embedding shape: {embeddings.shape}")

# Initialize FAISS index & add embeddings
dimension = 512
index = faiss.IndexFlatL2(dimension)
index.add(embeddings)

faiss.write_index(index, "/content/legal_index.faiss")
with open("/content/legal_metadata.json", "w") as f:
    json.dump(metadata, f)

print("Legal database created in Colab!")


from google.colab import files
files.download("/content/legal_index.faiss")
files.download("/content/legal_metadata.json")

